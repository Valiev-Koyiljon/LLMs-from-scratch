{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.3\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.8.0\n",
      "tensorflow version: 2.16.1\n",
      "pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac5034",
   "metadata": {},
   "source": [
    "### Shu yerga keldim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate_text_simple,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training accuracy: 57.50%\n",
      "Validation accuracy: 61.25%\n",
      "Test accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.669\n",
      "Validation loss: 0.717\n",
      "Test loss: 0.710\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.669, Val loss 0.727\n",
      "Ep 1 (Step 000050): Train loss 0.511, Val loss 0.598\n",
      "Ep 1 (Step 000100): Train loss 0.500, Val loss 0.542\n",
      "Training accuracy: 75.00% | Validation accuracy: 80.00%\n",
      "Ep 2 (Step 000150): Train loss 0.529, Val loss 0.496\n",
      "Ep 2 (Step 000200): Train loss 0.471, Val loss 0.457\n",
      "Ep 2 (Step 000250): Train loss 0.400, Val loss 0.433\n",
      "Training accuracy: 75.00% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.385, Val loss 0.410\n",
      "Ep 3 (Step 000350): Train loss 0.391, Val loss 0.398\n",
      "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
      "Ep 4 (Step 000400): Train loss 0.252, Val loss 0.405\n",
      "Ep 4 (Step 000450): Train loss 0.413, Val loss 0.371\n",
      "Ep 4 (Step 000500): Train loss 0.377, Val loss 0.362\n",
      "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
      "Ep 5 (Step 000550): Train loss 0.365, Val loss 0.357\n",
      "Ep 5 (Step 000600): Train loss 0.415, Val loss 0.342\n",
      "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
      "Training completed in 4.61 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWKRJREFUeJztnQdUFOfXxh86goAoNlRsqGDvvRu7xhITNdGY9iVqbDHNkkSjMaZa8o9dY2KaibFEY++9dwWxiyCClSogsN+577iwi4D0XeD5nTNnZ2dnZ94dln3mlvdeC51OpwMhhBBCzBJLUw+AEEIIIalDoSaEEELMGAo1IYQQYsZQqAkhhBAzhkJNCCGEmDEUakIIIcSMoVATQgghZgyFmhBCCDFjKNSEEEKIGUOhJoSki7Zt22LMmDGmHgYhBQ4KNSG5xGuvvQYLC4unli5duph6aIQQM8ba1AMgpCAhorx06VKjbXZ2diYbDyHE/KFFTUguIqJcqlQpo8XV1VW9tmvXLtja2mLv3r2J+3///fdwc3NDUFCQer5p0ya0bNkSRYoUQbFixdCjRw9cuXIlcf/r168rK/3vv/9Gq1atUKhQITRq1AgXL17E0aNH0bBhQxQuXFjdMNy5c8fI2u/duzc+//xzlChRAs7OznjnnXcQGxub6meR1z766COUKVMGjo6OaNKkifoMem7cuIGePXuqzyev16hRAxs2bEj1eHPnzkWVKlVgb2+PkiVLol+/fomvSe+gb775BpUqVVKfqU6dOvjnn3+M3u/j44Nu3bqpzyfvHzx4MO7evWvkuh81apQac9GiRdW1nzx5crr+boSYEgo1IWYWAxaBCQ0NxenTpzFx4kQsWrQIpUuXVvtERkZi7NixSnS3b98OS0tL9OnTBwkJCUbHmjRpEj755BOcOHEC1tbWGDhwoBKo2bNnqxsBEffPPvvM6D1yPF9fX+zcuRN//vknVq9erYQ7NV5//XXs378fy5cvx5kzZ/Diiy+qG4BLly6p1999913ExMRgz549OHv2LL7++msloilx7NgxJaJTpkyBn5+fuiFp3bp14uvyWcQTMW/ePJw/fx7vvfceBg0ahN27d6vX5UamTZs2qFu3rjqWvD84OBgvvfSS0Xl++eUXddNw+PBhJfxyvq1bt2b4b0VIriJtLgkhOc+QIUN0VlZWOkdHR6NlypQpifvExMTo6tWrp3vppZd0NWrU0L311ltpHjMkJETa1OrOnj2rnl+7dk09X7x4ceI+f/75p9q2ffv2xG3Tp0/XVatWzWhsRYsW1UVGRiZumzdvnq5w4cK6+Ph49bxNmza60aNHq/XLly/rLCwsdIGBgUbj6dChg278+PFqvVatWrrJkyen69qsXLlS5+zsrAsLC3vqtYiICJ29vb3uwIEDRtvffPNN3cCBA9X6p59+quvUqZPR6zdv3lSf28/PL3H8LVu2NNqnUaNGuo8//jhdYyTEVDBGTUgu0q5dO2UVGiJuWD3i+v7tt99Qu3ZtlC9fHrNmzTLaVyzhTz/9FIcOHVJuXb0l7e/vj5o1aybuJ+/XI25goVatWkbbQkJCjI4t7mQHB4fE582aNUNERARu3rypxmKIWOrijq5atarRdrGgxSUviIU8bNgwbNmyBc899xxeeOEFo3EZ0rFjR3UOcW2LVS6LeApkPOLSjo6OVvskd73Xq1dPrR8/flx5AlKy2OWa6ceZ/PziqUh+HQgxNyjUhOQi4nb19PRMc58DBw6ox/v376tF3qNHYr7lypVT7nB3d3cl1CLQyWPJNjY2iesSs05pW3J3eWro32+IvNfKykoJpDwaohfLt956C507d8b69euVWE+fPl3F3EeOHPnU8ZycnJT4S4xb9hW3vMSPxcWvH6ccR+LhKSXiyT5ybcS9nhx92CD5NcjodSDEVFCoCTEjxPqT+KsIsSSEvfrqq4mx6Hv37qkY8oIFC1SimLBv375sO7fExB89eqSStQSx2kV0y5Yt+9S+YsnGx8cra1Q/lpSQm4qhQ4eqZfz48epzpSTUgsTSxfKWRWLskjC3Y8cOZUmLIIvXQOLQKVG/fn2sXLkSFSpUUMchJD/BbzQhuYi4hm/fvm20TYRFMrtF+CSRrFOnTipRq2vXrspdLVbohx9+qLKnxa28cOFCZSWKcI0bNy7bxiZW+ZtvvqkStyRjW8RyxIgR6iYhOeJKfuWVV9SNhIxPhFtc8SKsMmbJvpbEOPkMsu+DBw/Ua97e3ime+7///sPVq1dVApl8TskOF0u3WrVqytr+4IMP1A2MbJOs97CwMOV5kBuJIUOGqMQ1uQmQpDm5VnI9L1++rBLdZHtyq5+QvASFmpBcRLKRDV2xgojRhQsXMG3aNDW9at26dWq7TB9avHixylwWq1IymkV4JPYr7m553w8//KCyxbODDh06qOlRIpZyQzFgwIA0py9JFvYXX3yB999/H4GBgeomQuLaItKC3HiIgAYEBKjpXhJ3njlzZorHEut51apV6nwSj5ZxSOa5TOkSpk6dqqaNiftcBF32Fyt6woQJ6nUJA0gG+scff6zc7TJ+iXnLOVO60SAkL2EhGWWmHgQhxLTIPOqHDx9izZo1ph4KISQZvNUkhBBCzBgKNSGEEGLG0PVNCCGEmDG0qAkhhBAzhkJNCCGEmDEUakIIIcSMoVBnAWnLV7FiRdWWr0GDBkbtCfMT0v1IyjPKXFUpuZh8Co+kOcj8V3ldqlrJvF7pcGSIzGuVilRSiEJKYj7//PNqfq0hUhRDCn64uLioRdZlylBeQOb3SjtJKc4h832lZaR0gTKkoF8nqXEutbZlTrUsMud648aNia8X9OuT2vdK/uekeIweXieozy/XxXCRugP59hqZrB1IHmf58uU6Gxsb3aJFi3Q+Pj6qq5B0Qrpx44Yuv7FhwwbdxIkTVYcj+cqsXr3a6PWvvvpK5+TkpF6XLk79+/fXlS5d2qgT0tChQ3VlypTRbd26VXfixAldu3btdHXq1NHFxcUl7tOlSxddzZo1VZckWWS9R48eurxA586ddUuXLtWdO3dOd+rUKV337t11Hh4eqvOTnoJ+ndauXatbv3696mYly4QJE9T/kFwzoaBfn+QcOXJEV6FCBV3t2rUTu5YJvE463aRJk1R3uaCgoMRFOsnl12tEoc4kjRs3Vn9oQ7y8vHTjxo3T5WeSC3VCQoKuVKlS6h9DT3R0tM7FxUU3f/589fzhw4fqB1lubvRIe0RLS0vdpk2b1HO52ZFjHzp0KHGfgwcPqm0XLlzQ5TX07Sd3796tnvM6pYyrq6tqycnrY0x4eLiuSpUqSkQM24vyOiUJtYhqSuTHa0TXdyZrIkvXIKnJbIg813c+Kihcu3ZN1a42vBbSQEGaJ+ivhVyrx48fG+0jLikpg6nf5+DBg8q11KRJk8R9mjZtqrblxWsaGhpq1MKS18kYKS8q5VAjIyOVC5zXxxgpvdq9e3fVoMQQXqckLl26pD6XhB+l3K2Uls2v14i1vjOBNB+QHxp9n1898jx5w4X8jv7zpnQtpLGDfh/psyzNFpLvo3+/PEpsNzmyLa9dU3E8jB07VjWP0PeI5nXSOHv2rBJmqectDTVWr16N6tWrJ/7wFfTrI8gNjLT8lBafyeH3SEPEc9myZarhS3BwsKo537x5cxWHzo/XiEKdBZL36ZUf6JR69xYEMnMtku+T0v558ZpKx6kzZ86k2IKyoF8naSRy6tQplZAjbSml89Xu3bsTXy/o1+fmzZsYPXq06sktSaqpUdCvU9euXRPXpVub3PxVrlwZv/zyi7J689s1ous7E0iWoLTNS35XJb15k9/F5Xf0mZZpXQvZR8IFkkGZ1j5yZ5ycO3fu5KlrKlmka9euxc6dO436OPM6aYgV4+npiYYNG6qM5jp16mD27Nm8Pk8Ql6x8HplFIu1PZZEbGemSJuv6z1DQr1NyJGtbBFvc4fnxu0ShzuSPjfwjbd261Wi7PBf3S0FC4kPyhTa8FvIPID8u+msh18rGxsZon6CgIJw7dy5xH7kjlrjukSNHEvc5fPiw2pYXrqncZYslLa0ape+yXBdDeJ1Sv24yTYbXJ6nVqIQHxOugX+SmRnp/y3qlSpV4nVJAvkO+vr6qhWy+/C7laupaPpyetWTJEpUdOGbMGDU96/r167r8hmSgnjx5Ui3ylZkxY4Za109Fk+xKyahctWqVmgoxcODAFKdClC1bVrdt2zY1FaJ9+/YpToWQqSiSWSlLrVq18sx0kWHDhqlrsGvXLqMpI1FRUYn7FPTrNH78eN2ePXt0165d0505c0ZNz5Is2y1btqjXC/r1SQ3DrG+B10mne//999X/2tWrV1VWtoxbpmPpf3/z2zWiUGeBOXPm6MqXL6+ztbXV1a9fP3EqTn5j586dSqCTL0OGDEmcDiHTJWRKhJ2dna5169bqn8OQR48e6UaMGKErWrSorlChQurL7u/vb7TPvXv3dK+88or6h5NF1h88eKDLC6R0fWSRudV6Cvp1euONNxL/X4oXL67r0KFDokgLBf36pFeoeZ10ifOixVhyd3fX9e3bV3f+/Pl8e43YPYsQQggxYxijJoQQQswYCjUhhBBixlCoCSGEEDOGQk0IIYSYMRRqQgghxIyhUBNCCCFmDIU6i9VwpDm5PJLU4XV6NrxGz4bX6NnwGuXPa8R51FkgLCxMtTyTknLOzs6mHo7Zwuv0bHiNng2v0bPhNcqf14gWNSGEEGLGUKgJIYQQM6bA9aOOi4vDyZMnVZsyS8us3aeEh4erx8DAQOVOISnD6/RseI2eDa/Rs+E1yjvXKCEhQbXRrFevnmphmhYFLkZ99OhRNG7c2NTDIIQQQiBtNBs1apTmPgXOotY3/JaLI71LCSGEkNxG+l+L0ajXpLQocEKtd3eLSJctW9bUwyGEEFKAsUxHCJbJZIQQQogZQ6EmhBBCzBgKNSGEEGLGFLgYNSGEpEV8fDweP35s6mGQPI6NjQ2srKyy5VgUakIIASAzVW/fvo2HDx+aeigkn1CkSBGUKlUKFhYWWToOhTqr+G0E7vgBLceYeiSEkCygF+kSJUrAwcEhyz+upGDf9EVFRSEkJEQ9z+pUYAp1Vrh1EvhzAGBhCXg0AzyamHpEhJBMurv1Il2sWDFTD4fkAwoVKqQeRazle5UVNziTybKCez2g9gBAlwCsfgeIiTD1iAghmUAfkxZLmpDsQv99ymrOA4U6q3T9GnAuCzy4Bmz91NSjIYRkAbq7iTl+nyjUWaVQEaD3HG392E/Apa2mHhEhhJB8BIU6O6jUFmgyTFv/dwQQdd/UIyKEkEzTtm1bjBmT/gTZ69evK+vx1KlTOTquXbt2qfMUtMx8kwv13LlzUbFiRdjb26NBgwbYu3dvqvu+9tpr6o+UfKlRowZMznOTALeqQMRtYP1YSfsz9YgIIfmclH4PDRf5zcwMq1atwtSpU9O9f7ly5VSTiZo1a2bqfMSMhfqvv/5Sd20TJ05UPaJbtWqFrl27wt/fP8X9Z8+erb4M+uXmzZsoWrQoXnzxRZgcm0JAnwWAhRVwfjVwbqWpR0QIyecY/h7OmjULzs7ORtvkN9OQ9CY1ye+qk5NTuschGc0yX/hZfZVJHhTqGTNm4M0338Rbb70Fb29v9UWTO7N58+aluL+Li4v6MuiXY8eO4cGDB3j99ddhFpSpD7T5SFsXqzrslqlHRAjJxxj+Hsrvo1jR+ufR0dGq4Mbff/+tXNnitfztt99w7949DBw4UHUPlKzkWrVq4c8//0zT9V2hQgV8+eWXeOONN5SAe3h4YOHCham6vvUu6u3bt6Nhw4bqPM2bN4efn5/Reb744gs1dUmOKTowbtw41K1bN0PXYOXKlcqramdnp8b5/fffP+W1rVKlivr80lKyX79+ia/9888/6vPLVCqZlvfcc88hMjIS5obJhDo2NhbHjx9Hp06djLbL8wMHDqTrGEuWLFEXtnz58qnuExMTg7CwsMQlPDwcOUqr9wH3+kB0KPDvu3SBE5KXi1bExplkkXNnFx9//DFGjRoFX19fdO7cWQm4hBn/++8/nDt3Dm+//TYGDx6Mw4cPp3kcEUARXfF+Dh8+HMOGDcOFCxfSfI94S+V9YlSJtS1Cr+f333/HtGnT8PXXXystEPFPzUhLDXnfSy+9hAEDBuDs2bOYPHkyPv30U/z888/qdTmvfPYpU6aom4RNmzahdevW6jXxOMgNi4xJro3cXPTt2zdbr312YTI/xd27d1WRgeRNs+W5VAh6FnKRN27ciD/++CPN/aZPn47PP/8cuYaVjeYCX9AKuLIDOLoYaPx/uXd+Qki28OhxPKp/ttkk5/aZ0hkOttnz8yyWsQiQIR988EHi+siRI5WArVixAk2apF60qVu3bkqg9eI/c+ZMJW5eXl6pvkeEuE2bNmpdrOXu3burGwWxbv/3v/8pj6reI/rZZ59hy5YtiIiIyJBXtkOHDkqchapVq8LHxwfffvutis9LGNXR0RE9evRQVrsYdfXq1UvUkLi4OHVt9MaeWNfmiKW5zTOTu5n0zD2TOyZx6/Tu3TvN/caPH4/Q0NDERf6IOU7xqkDHKYCtE2CX/jgPIYRkN2IFGyIGkgho7dq1lbu3cOHCSiBTyw3SI/vr0bvY9SUy0/MefRlN/XvEwm3cuLHR/smfPwtfX1+0aNHCaJs8v3TpkvqcHTt2VCJcqVIl5TUQK15Kewp16tRRIi/iLHlOixYtUqFUc8RkFrWbm5tKQEhuPcsfMbmVnRwR859++kldeFtb2zT3lbiFLHrE/Z0rNPo/wLsn4OyeO+cjhGQrhWyslGVrqnNnF2JRGiKuaLGGJSdIREpeF6tbwpHP6gZliIh1QkJCut+jN8AM35OSoZYRdCkYdobHECv6xIkTyvKXmxGx2sU9fvToUWXobd26VYVa5TWx8MVVLyEAmYlkTpjMohaBlTiJXChD5LkkHaTF7t27cfnyZeU2MVssLY1FOj7OlKMhhGQQEQBxP5tiyckKaTIFtlevXhg0aJCyKsXaFAs0t6lWrRqOHDlitE1iyhmhevXq2Ldvn9E2EV5xgetra0tsXHKZvvnmG5w5c0Ylvu3YsUO9JtdZLHAJj0rsXXRp9erVMDdMmks/duxYZRWLa6ZZs2Yqi1DcL0OHDk10WwcGBmLZsmVPJZFJLCXPzNm7shNYNxp46RetPjghhJgIT09PlSktgubq6qrivOLZlJk3uYnExv/v//5P/f6LcSbTdUVI5cYhvbz//vto1KiRmvPdv39/HDx4ED/++KPK9BYkYe7q1asqgUw+64YNG5RFLzcJYjlLVrokMEvmuTy/c+dOrl8HsxdqubAyVUAy8vST5eVC6gP7si153ETizPIlSz4/0Kw5/jPw8Aaw62vg5eWmHg0hpAAjiVfXrl1TGeAybUqyviXXR35bc5NXXnlFiagktkmCmWRvSwJYcis7LerXr6+mn4lLW8Ra4uCiJ/pCL+LeluIt4u6Wc8g0LZmKJtO5JL69Z88eFQKQkKjojoQFpJaHuWGhM8dc9BwkICBAzdWWYikyjzBXiLwHHJgNtPkYsDWOFxFCTI/8iIt46askEtMgyV+SpPbrr78iv3+vAjKgRSwjkxs4FtOywAkhhCgk+3r+/PnKspd4sli627ZteypviZjB9KwCh2Q8Hl2iFUQhhJACiiRySahTSkdLYvG6detUWFMSv4gxtKhzm7UjgVO/AQHHgD4Zq8JDCCH5BSnbKRY0eTa0qLNAwIMofLjiNO5Hpj3/0Ij6g+VeEjj9B+C7LieHRwghJB9Aoc4Co/48iRXHAzBr28X0v8mjKdBitLYuU7Yi0q7sQwghpGBDoc4CH3Suph5/P+yPyyEZaPbRbgJQsiYQdQ9YO4qNOwghhKQKhToLNK/sho7VSyI+QYdp633T/0ZrO61xh5UtcHEjcPK3nBwmIYSQPAyFOotM6OYNGysL7PS7gz0X76T/jaVqAu0mauubxgEPrufYGAkhhORdKNRZpKKbI15tVkGtf7HeB3HxaRepN6L5SMCjGRAbAawZDiTE59xACSGE5Eko1NnAqPZVUMTBBheDI/DXsZvpf6OlFdB7HmBbGLixHzg4JyeHSQghKdK2bVvVQUtPhQoVVGnNZ82DXrNmTZbPnV3HSQspIVq3bl3kVSjU2YCLgw3GdKii1mdsuYiw6Mfpf3PRikDnL7X1HVOB4Fzol00IyRf07Nkz1QIh0qBCRFDaPGYUaQMpNcBzQyylp4M51tc2JyjU2cQrTcujUnFH3IuMxZydlzP25vqvAlW7APGxwKq3gbgMzMsmhBRYpNWvtGy8cePGU6/99NNPShilcUVGKV68uGrYkRtIbW87O7tcOVdehUKdTdhYWWJiN6092tJ913HzflT63yy9Z3v+ABQqCkQ/BEIz4D4nhBRYevTooVo0/vzzz0/V0Za2kSLk0qFw4MCBqvGDiG+tWrVUXe20SO76ln7V0ipSGktID+iU6nF//PHHqg+0nENaVUqXrsePNe+ijE96Pp8+fVpZ+bLox5zc9X327Fm0b99eVS4rVqyYsuwjIiISX5fOWNLt67vvvlPdsmSfd999N/Fc6UFaXUqXLbkmcpMgNzSbNm1KfD02NhYjRoxQx5fPLNdj+vTpRt4BDw8P9V53d3eMGjUKOQlLiGYj7b1KoKWnG/ZdvouvNl7AnFcycCfrVBJ4ZQXgVgWwd8nJYRJCMkJsZMbfY2UHWD35eY2PA+JjAAtLwKbQs4+bgQ571tbWePXVV5XoSatHET1hxYoVSmyklaSIttTSFiF1dnbG+vXrMXjwYCWmTZo0SZeo9e3bF25ubjh06JBqCWkYz9bj5OSkxiHCJWIrvaZl20cffaRaGp87d06Job5sqIvL079zMtYuXbqgadOmyv0eEhKCt956S4mm4c3Izp07lYjK4+XLl9XxRWzlnOlB2iRLS8sFCxagXr16yvvw/PPP4/z586oV5g8//IC1a9eqFpoiyNLhShbhn3/+wcyZM7F8+XLVLlN6ecsNSE5Coc5G5J/kkx7e6DZ7L9afDcJr1++jUYWi6T9A2YY5OTxCSGb40j3j73nxZ6BGH239wjpgxWtA+ZbA6+uT9plVSyt6lJzJGWvY88Ybb+Dbb7/Frl270K5dO7VNhEfE1dXVVS3S81nPyJEjlWCKmKdHqEVYpXfz9evXE9sxfvnll0/FlT/55JPEdbFA33//fWXVi1CLdVy4cGF1YyGu7tT4/fff8ejRIyxbtgyOjtoNy48//qhi8V9//TVKliyptslnku3SdcvLywvdu3fH9u3b0y3UYo3LjcuAAQPUczm2iL54EebMmQN/f38l2C1btlS/69KrWo+8Jp9BcgNsbGyUkDdu3Bg5CV3f2YxXKWf0b1ROrU/9zwcJCZmoOiaVyo4tBbYkffEJISQlRKiaN2+uxFm4cuUK9u7dqwRciI+Px7Rp01C7dm3lJhbB3LJlixKc9CAiLWJk2DO5WbNmT+0nlqYIm4iYnENc3+k9h+G56tSpkyjSQosWLZRV7+fnl7hNLFkRaT1iXYv1nR7EI3Dr1i11XEPkuZxf714/deoUqlWrptzacr30vPjii+pmQjwScmOwevVqxMXFISehRZ0DjO1YDetOB+FMQCj+PR2IPvXSbgr+FEGngP+euJa8emj1wQkhpmHCrcy5vvV49dSOIa5vQ8acRXYhsWhxD4s1uHTpUmUBdujQQb0mLl5x1Yq1KPFpEUFxXYtrPD3oUihxrHex6xGXuFinEoeW/tLi1hbXsJw7I8i5kh9bj+F2sWSTvyZinhGSn8fw3JKAd+3aNWzcuFF5FF566SVlQcvNSLly5dRNg8Tp5bXhw4crj8bu3bufGld2QYs6ByjuZIfh7Sqr9W82+eFRbAYLmbjX0xp3dJoGlM1Zlwoh5BlIzDijiz4+Lci6bDOMT6d13EwgQiIW5h9//IFffvkFr7/+eqLoiHXdq1cvDBo0SFmrYglKclh6keQxsYzFCjWc+mXI/v371c3BxIkT0bBhQ+U2Tp6Jbmtrq6z7Z51LLNnIyEijY1taWqpEtexA4vQSR9+3b5/R9gMHDsDb29toP4l9L1q0SLnwpVf2/fv31WviypeYtsSyJeQg10Pi8jkFLeoc4o0WFfH7IX8EPnyEhXuuYvRz2jzrdNNxSk4NjRCSzxBXs4jKhAkTEBoaqly3ejw9PZXIiBBJbHfGjBkqAcpQlNJCLElxAUvSmljI4joWQTZEziFiLlZ0o0aNVMKauIQNkbi1WKkixOJGl0Sz5NOyJPlt0qRJGDJkiMqsvnPnjoqpS/KbPj6dHXz44YfqPJUrV1ZJaOKFkHFJjFwQD4S40+U1uUmQeL649IsUKaKS2uSGQ+L7kuH+66+/KuE2jGNnN7Socwh7GyuM6+ql1ufvvoLgsOjMH0yyQwOOZ9/gCCH5DnF/P3jwQAmrxJT1SKxYXLnikpYKZCI4Mr0pvYhQiejGxMSopCnJwpaYtyFisb/33nvK/S7iJjcFcl5DXnjhBZXRLQlvMk87pSliInybN29WlqsIfr9+/ZQLXxLHshOJO0uymywSDpDkOsnyFk+A/sZHEszEOyDjkES6DRs2qGshYi1WtsS0Je4vSWzr1q1T8f+cwkKXUgAiHxMQEKBiDJJqb5gckRPIpe03/yCO33iAfg3K4rsX62T8IA/9gWW9gai7wPBDgHMmMlAJIWkSHR2trL2KFSuqebOE5PT3KiNaRIs6p6drddfcSytPBOBcYMamXSicSgP2zkB0KPDvu+xdTQghBQwKdQ5Tz8MVveq6K32d8p9PihmUaWJlA/RZCFjbA1d2AEcX59RQCSGEmCEU6lzgoy5esLO2xJFr97H5fHDGD1C8KvDc59r6lk+BuxmsJU4IISTPQqHOBcoUKYS3W1dS69M3+iImLhN9pxu/DVRsA8Q9Ala/o5UlJIQQku8xuVDPnTs3MdAu9Whlzl9aSOahTA2QVHhJ7Zf0en1FHnNmaJvKan71jXtRWHbg6U43z8TSEug9F7BzAQKPAftm5sQwCSGEmBkmFWqZRC4VckR4T548iVatWqn6sWmVnZOJ/ZIOv2TJElUdRlL8pYSeueNoZ40PO1VT6z/suIT7kZloZelSFuj2rba++yvg1qlsHiUhBZuMVrciJDe+TyadniUTxmV+37x58xK3ySR8meNn2FJMj8x1kzJ1V69eRdGiGWh2YaLpWcmJT9Ch5//2wScoDK82K48pvWpm/CDy5/r7VcB3LVDcC3h7N2DD6SSEZPUHVap1SXUvmeMrVbRSK2VJyLMQWZUSrVKwRYqjyPxsmYOdWS0yWWUy+RDHjx/HuHHjjLZ36tRJTZZPCZmQLhPQv/nmG1UNRmrWShm3qVOnqsowqbnKZdETHh4OU2FlqXXXennRYfx+2B+Dm5ZHlZJOGTuI/Hj0mAX4HwLuXAC2TwG6fJlTQyakQCA/ohKCCwoKMiqVSUhWkAIuUnwmuUhnFJMJ9d27d9WdRvKycPJcytulhFjSUp9V4tlSKUeOIQXRpYpNanFqscylULy50LyyGzpWL4mtPsGYtsEXP7+eiVrejsWAXj8Cf7wEHJqjtcqT+LVlUjcZQkjGECtaflSlE9KzalIT8izEOyNtPbPDM2PyWt9pdTBJyT0lr0k9Vn3TcalbK2XmpGtMSlb1+PHjMXbs2MTngYGBqvC7KZnQzRu7/EKwy+8Odl+8gzZVi2f8IFU7A20nALumA9Z2FGlCsgH5fZEOSDnVBYmQPJVM5ubmpu44klvP0lM0teLrUiS9TJkyiSKtj2mLuIu/PyUkM1y6oOgXKQRvaiq6OeLVZhXU+rT1PoiLz2TCQduPgbe2Ax0/Ny45ev9qNo2UEEJIgRVqcTPJdCzp6WmIPJcm6CkhRdAlfhQREZG47eLFi8r/n9uJYVllVPsqKOJgg4vBEVh+9GbmD1S2AVDINSnRbN1oYG4z4NyqbBsrIYSQAjo9S1zSixcvVvFlX19f1X1FpmYNHTo00W0trdX0vPzyy6pDifRa9fHxwZ49e1S7sjfeeCPVZDJzxcXBBmM6aJ1aZm69iLDox1k/aGwEkBCvCXbpTDQAIYQQYnaYVKilf+qsWbMwZcoU1RpNhFdaien7ekoGpuGcamk9Jhb3w4cPVfa39C7t2bOnat6dF3mlaXlUKu6Ie5GxmLMzG8qC2jkBr/4LvL0LKFY5abvPv0CM6bLdCSGEZB62uTQx232D8eYvx2BrZYltY9vAo5hD9p7g5hFgSSfAuQzQ/XugWpfsPT4hhJAMwzaXeYj2XiXQ0tMNsfEJ+GqTb/afICEOKOIBhAUAf/YH/h4ChKc8/Y0QQoj5QaE2h57VPbxhaQFsOHsbR6/fz94TlG8ODD8EtBgNWFgBPmuAHxsDx3+W+W7Zey5CCCHZDoXaDPAq5Yz+jTzU+tT/fJCQkM3RCFsHoOMULXbtXg+ICdWyw3/uDty5mL3nIoQQkq1QqM2EsR2rorCdNc4EhGLNqcCcOUnp2tq8687TARtHwP8AML8FsOsrIC6pzCohhBDzgUJtJkgLzOHttEztbzb5ISo2h/pNSwWzZsOBdw8BVToB8bFadbP5rYAbB3PmnIQQQjINhdqMeKNFRZQpUgi3w6KxaM+1nD2ZJJi9/DfQbyngWAK46wcs7QIcnJuz5yWEEJIhKNRmhL2NFcZ11Xprz999BbdDo3P2hFJTvWZfYMQRoP6rgJUtULl9zp6TEEJIhqBQmxk9apdGg/KuePQ4Ht9u9sudk0oJ0uf/B4w6CZTQbhQUp/4AQlOuoU4IISR3oFCb43St7t5qfeWJAJwNCM29k7sYTLq/dRL4911gThMgNIeS2wghhDwTCrUZUs/DFb3quqv1qet9VHewXEeywss0BKp2AVzK5P75CSGEKCjUZspHXbxgZ22JI9fuY/N5E1QSK14VeGMz0HN20rawIGDHNODxo9wfDyGEFFAo1GaKZH+/3bqSWv9ywwXExMXn/iAsLQG7wknPN34E7PlGa6N5dVfuj4cQQgogFGozZmibymp+tf/9KCw7cMPUwwFq9wec3IEH14BlvYA1w4GobC55SgghxAgKtRnjaGeNDztVU+s/7LiEexEmrh7m3QN49zDQ+G1JewNO/Q7Mrgvs/pZtNAkhJIegUJs5LzQoi+qlnREeHYdZ2y6ZejiAvTPQ7Vvgza1AyVpa3fCdXwCz6wAH/sf4NSGEZDMUajPHylLrriX8ccQfl4LNxHIt1wh4Zw/wwhKgmCcQdQ/Y8olmYR9ZBMTFmnqEhBCSL6BQ5wGaV3ZDx+olEZ+gw7QNOdCzOivJZrX6AcMPA73mAC4eQMRtYMMHwI8NgItbTD1CQgjJ81Co8wgTunnDxsoCu/zuYPfFOzArrKyBeoOAkceAbt8BhUsCD/0Ba9scOd3F4HDM2HoRb/x8FMuP+JtmnjkhhOQS1rl1IpI1Kro54tVmFbBk3zV88Z8PWoxuBWsrM7vPsrYDGv8fUPcV4MJ6oFLbpNeO/6w1/6jWVasxnkHE5b/+bBDWnwnCpZCIxO07LoTgvzNBmN63FsoVdciuT0IIIWYDhToPMap9FVVWVIRq+dGbGNS0PMwSWweg9otJzyPvApsnArERwKBVgGeHdB3mckiEEub1Z2/hYnCSONtaWaJ1VTdULlEYP++/jn2X76LzrD2qocmgJuVhaZnxGwFCCDFXKNR5CBcHG4zpUAWT1/lg5taLeL6uO5ztbWD2WFprlrb/YePuXCLgjm5Gu165E4ENSpyDcOF2UuKcuP1bVymO7rVL47nqJRM/d/+G5fDxyjM4ev0BPvv3vBL2b/rVRvlijrn3+QghJAex0GUiwHfz5k3VPKJsWa2Jw5EjR/DHH3+gevXqePttmWNrvgQEBKBcuXLqM+jHn5d4HJ+ALrP24MqdSLzTuhLGd9MywvME8lXTu71jIrQpXe71EFD/fay57aZc2IbibG1pgVZV3NC9trtKpnMplPJNSUKCDssOXsfXm/xU1zF7G0t82NkLrzWvoLLmCSEkL2tRpoKcL7/8Mnbu3KnWb9++jY4dOyqxnjBhAqZMmZK5UZN0YWNliYlPumst3X8d/veikGcwiE0Hn92OhKgHwOWtKPt3F1TaORzxwb5KnNtWK45v+9XG8U86YunrjdGvQdlURVoQV/drLSpi85jWaFapGKIfJ2Dqfz54acFBZaETQkheJlNCfe7cOTRu3Fit//3336hZsyYOHDigrOqff/45u8dIktGuWgm09HRDbHwCJq87j3OBoQiLfgxz58a9SMzddRndf9iLJv9Yo13Mt1gd3wIJOgt0szqCLXYfw6fuKvzcyw0vNiynXP0ZwaOYA35/qwm+6F0TjrZWOH7jAbrN3osFu6+oqW2EEFJgYtSPHz+GnZ2dWt+2bRuef/55te7l5YWgoKAMHWvu3Ln49ttv1ftq1KiBWbNmoVWrVinuu2vXLrRr1+6p7b6+vurcBapndQ9vJUKS9SyLUMTBBh5FHVT2s3p01R5lKV3EXlnjuY1Y/BJv3nA2CGcDk3pri0vao3JNxNbuiPASD+Fy6BtY+K6Drc8KwHeVNt2rzUfGPbLTgVjXkmTXzqsExq08g72X7mL6xgvYcO42vutXG1VKOuXApySEEDOLUTdp0kQJZvfu3dGpUyccOnQIderUUY/9+vVTvvf08Ndff2Hw4MFKrFu0aIEFCxZg8eLF8PHxgYeHR6pC7efnB2dn58TtxYsXh5WVVYGIURuy6kQAfjl4AwH3o3AvMu1KYCKM7kXsE8VbL+b6RURebgCyg5v3o5Qwi0CfCTAWZ3FNS0JY5xqlUNQx2TzrWye1NpqXtz55gy3Q8E2g1VigcIkMj0O+2iuOBaie3lKCVbLFRz9XRXUlM8VNCyGEZEaLMiXUIph9+vRBWFgYhgwZgp9++kltlxj1hQsXsGrVqnQLfv369TFv3rzEbd7e3ujduzemT5+eqlA/ePAARYoUQWbIT0JtSERMnBJI6bQlj/p19fzBI8TGJaT5/sJ21k/Eu1CieJfVP7oWgp112jdCAQ/04nwbp28+TNwuuVzNKhdD91ru6FyjJIoV1jwxaXLjILDjC+DGPu25jQPQ5B2g1fuAXcYt4tuh0Ziw+myi56FmGWd8268OvEsn3ewRQki+EmohPj5eCbWrq2vituvXr8PBwQElSjzb+omNjVX7rlixQom+ntGjR+PUqVPYvXt3qkJdoUIFREdHqyzzTz75JEV3eEET6rSQrOg7ETGacN8T4U4SdHkMDku7K5cY2qWc7Y1d6sUKwd2lkHJnS7b2qWTi3LRSMXSrVRpdapaCW3rEOTnytZSe1zumAoHHAcfiwOjTgG3mpl3J13z1yUB8vs4HoY8eq6S1d9t5qsXWmtY1ISR3yYgWZSpG/ejRI/XDpxfpGzduYPXq1coa7ty5c7qOcffuXSX2JUuWNNouzyWTPCVKly6NhQsXokGDBoiJicGvv/6KDh06KAFv3bp1iu+R/WTREx5uJk0tchGJ25Z0tldLowpFn3o9+nE8Ah48MrbCDR4jY+MRFBqtliPX7qcq5k0qFlVTqbrUKKX6aGcJOWDldlp1M7+NwOOoJJFOSABO/QbU7KcVV0nX4SzQt35ZlYT3yZpz2OITjNnbL2Hz+dvKuq5V1iVr4yWEkBwiU0Ldq1cv9O3bF0OHDsXDhw+VC9vGxkaJ74wZMzBs2LB0Hyt5XFRuAFKLlVarVk0tepo1a6buRr777rtUhVpc6J9//nm6x1MQsbexgmeJwmpJjvw97kfGKvd5ooA/scplEataYs5iOZdwss/+wcl3waub8TafNcDakcCh+cCw/RkqSVrC2R4LBjdQXoBJa8+redu95+5Xc9Ilfv0sFz8hhOQJoT5x4gRmzpyp1v/55x9lBZ88eRIrV67EZ599li6hdnNzUwlgya3nkJCQp6zstGjatCl+++23VF8fP348xo4dm/g8MDBQucxJ+pCbJokry1K3XObyArIdSTKTTl0i4HqRFiv74XWgaKV0faaeddzRvHIxfLZWq2Y2d9cVZWXL/O16HknhHEIIMTWZCs5FRUXByUlL6tmyZYuyri0tLZVoihs8Pdja2ioX9tatTzJ8nyDPmzdvnu6xyA2CuMRTQ6aRSYa4ftGPm+RhvHsAI48DLUYnbbu8DfihPvDHAODqbi3G/Qzk5mPOy/Uxf1B9uBW2VbXFX5h3AF9u8FXhAEIIybNC7enpiTVr1ii38+bNm9UULb01bDht6lmIpSvTsSRrXOZCv/fee/D391cudb01/OqrrybuL3Os5byXLl3C+fPn1etixY8YMSIzH4PkZaSFpmEGuCScQQdc3Agsex6Y3xI4+RvwOPqZh+pSszS2vtcGveu6Q+qiLNxzVc1RP3Y95Xg8IYSYvVCLe/uDDz5Q2ddSoUxixXrrul69euk+Tv/+/ZX4StnRunXrYs+ePdiwYQPKl9e6QkkRFBFuw0xxOW/t2rVVUZR9+/Zh/fr1yqInBZx244ERx4FG/6dN5wo+B/z7LjCrJrBzOhChTc1KDVdHW8waUA+LX22Iks52uHo3Ei8uOIjP151HVGxcrn0MQgjJtulZElsWIZVCJ+L2FqTet1jU5lwlrCBOzypwPHoAnFgGHF4IhAUkxbUlS7zpMKB07TTfLtO3pOf3iuPae2VK2tcv1FbzwQkhJM/MozY8mSTnlClTBnkBCnUBIj4O8F0LHJoHBBxJ2l6hlSbYVbsAlqlnee/yC8GEVWdxK1Rznw9uWh4fd/VSxWEIIcSsu2clJCQod7WLi4tyU0u5T6kUNnXqVPUaIWaBlTVQsy/w1lbgre1AzRcACyvg+l7g71ef6Q5vW60ENr/XGi830crZ/nroBjrP3IN9l+7m0gcghJBMTs+aOHEilixZgq+++krV6BajfP/+/Zg8ebKqGDZt2rTsHykhWaFsQ6DfT0DHKcCRRVoBFWeD2QLHfgIqdwBctfwIPU72NviyTy10r1UaH688owrDDFpyGAMalcOE7t5wts9Yhy9CCMkomXJ9u7u7Y/78+Ylds/T8+++/GD58uJqrbK7Q9U2eIuQCMLcJYGkDvH8BcHRLcbfImDh8s+mCaoQilHaxx48v10OD8k9XeyOEEJO6vu/fv59iwphsk9cIyVMkPAYqtQOqdjYW6ev7gLikrmSOdtb4vFdN/PV2U1Qo5qBKqg5YeAh/HE6amUAIIdlNpoRaMr1//PHHp7bLNpk6RUieolQt4NU1QL+lSdvuXwN+7gHMrg3s+Q6ISroBbVKpGNaPaoVutUrhcbxOdeYav+oMYuJYJIUQYiYx6m+++Ub1ot62bZuaQy1Z3wcOHFAmvMyDJiTPFlHRc/+q1gM7PEjr4LXnW6DOAKDpcKB4NWVdS1Wzebuv4NvNfvjzyE1VN3z+oAaq+QkhhJjUom7Tpg0uXryo2lNKUw5xd0vREakWtnSpgVVCSF7FswMw5hzQZwFQqjYQFw0c/xmY0xj4ta8qWSpVxoe39cTS1xrB2d4aJ/0fosf/9rGiGSEkW8nyPGpDTp8+jfr166v2leYKk8lIhpF/kRsHgENzgQvrtVKlQjFPoEpn1YrT36ku/m/5BfgFh8PGygKTetbAK008Uu0ERwgp2ATkdDIZIQUKEdsKLYABvwOjTmrub1sn4N5l4NAc4I8X4bHIG2tbXFUtPyVuLT2vx686y7g1ISTLUKgJyQhFKwJdpgNjfbR52fWHAEU8gIQ42JXywo8D62FcVy+0tzqJDqdGY87s6bj9pLIZIYRkBtZCJCQz2Dtrlc5k0WeJu5RVru6hbSrj+YBAuF86gYAHxVXcet6g+mhU1hE4txKo2AZwyRsldwkheUyon9WlShLLCCmwlrYB7h1H4UGJyjhz2gl378Zg4MJDmNMiCp2PDtN2cKuqYttqqdASsHcxzbgJIflLqKW297NeN+wfTUiBpYQ3XDt6Y1qbODz+5wz+OxOEZfsvw9vFG+Wi/WBx9yIgy5GFgIUl4F4/SbjLNQas7Uz9CQgh+THrOy/ArG+S28i/2MI9V/H1pgtI0AHNy1jhx+aRKHr7AHB1l5aUZoh1IaB8c020K7cHStU01dAJITkEs74JMSMkbv1Om8r45Y3GcClkgwOB8ei00RlHqk8ERh7X5mv3mgPUehFwLA7EPQKubAe2fgps/Mj4YGFBpvoYhBATQaEmJJdoVaU41o1oCa9STrgbEYuXFx3CsoPXoXMpC9QbBLywGPjgEjDsINB5ujZHu1rXpANIGdMZ3sDsukBspCk/CiEkF2HWNyG5iEcxB6wa3hwfrzyLdadv4bN/z+NsQCim9q4Jexsrbc52yera0my48Ztvn9Hi2db2gK1j0vZ1Y7SYdoVW2nzvQq65/rkIITkHhZqQXMbB1ho/DKiL2mVcMH2jL1YcD1AVzaROuHuRQqm/UWLWH18Hwm4lbYuLAU7/qZU4PTxfHO1A6dqaaFdsDXg006aSEULyLEwmI8SE7Lt0FyP+PIGHUY/hVthWNfqQ7lzpRoTabyNwbQ9wfa+WSW6IhRXgXg+o+ES4yzUFbB2y/XMQQnJOiyjUhJiYm/ej8M6vx+ETFAZrSwt80t0bQ5pXyFydcEk2kz7a1/do4v3guvHrljZA2YZAn/mAa4Vs+wyEkIxBoU4DCjUxRx7FxuPjlWew9rTm1n6hfllM6/Mkbp0VHt7ULG0R7Wt7gbAATazH+SdZ1seWApF3gRp9ADfPbPg0hJDs1CLGqAkxAwrZWmG2xK3LuuDLDb5YeSIAF4PDsWDwM+LWz6JIOaDuy9oi9+QPrgEhvsbu72M/aYlqUl1NL9ShgUDEbaBUHcCKPxOECKFRj3HjfiRqly2C3ITTswgxE8TV/VarSvjtzSZwdbDB2cBQ9PzfPhy8ci+7TgAUrQR4dU/aJuLd4DWgei8tAU3PmeXAovbANxWBP/oDB+cAQWeAhITsGQvJNDJL4HJIuKmHUaCIi09QUynbfLcTQ389rjxguQlvlQkxM5p7umHtiJaJcetBSw6ruPVrmY1bp4Ucr9Gb2mJIXCxg5wLEhAIXN2mLIFO/pDZ5hdZaxTTXioBTKe04JMc5dPUeBi46pN1flXfFy409VGvVLIdISKrs8gvBtPW+uBQSoZ6XKGmH22HRqOhmMEUyhzF5jHru3Ln49ttvERQUhBo1amDWrFlo1crgzj4V9u/fjzZt2qBmzZo4depUus/HGDXJK8hd+/hVZ7DmlBa37luvDL7sWyv3fpQT4jWXuD6+7X8QiNV+rJ4qeepaXiva0nxk0nvvX9VagLJuebaQkKBDrzn7lafFEKl217d+GbzSxAOeJZxMNr78xuWQcHyx3he7/O6o50UdbTG2Y1UMaFQO1laWBSdG/ddff2HMmDFKrFu0aIEFCxaga9eu8PHxgYeHR6rvCw0NVc0/OnTogODg4FwdMyG5Gbee2b8uaqr51hew6mQgLoZI3LohymQlbp1eLJ9M7ZKlxWgg/jFw65SWUX7jAHD3EhAaoJU8vXMBiA5Lem/oTeDHhoCNAzA+ELB88sN2Yb12HImHizVu7nO8ZfqbVIR7dB+Iupe02DlrVePsck8Y1525pUS6sJ01/n6nGXZcCMafR24i8OEjLN1/XS2NKxTFy0080KVmKVrZmeRBZCxmb7+EXw/dQHyCDjZWFsqbNaJ9FXVTZApMalE3adIE9evXx7x58xK3eXt7o3fv3pg+fXqq7xswYACqVKkCKysrrFmzhhY1yfccuCzzrU/ifmSsurP/8eV6aF7ZzdTD0kT3ob+WpObiARSvqm33Pwz82lv16MaIo0n7L2gNBJ1Oel6oaJJoJ3/Mbpe6XnT1YiutRp1La68FngAOzdPG+9ykpPd8XQF49CDl48lNSPXeQL1XgPItctT9H/04Hh2+361E+cPO1fBuOy3pT4Rkz6U7+OOwP3ZcCFHPhSIONmrmwMDGYmUXzrFx5Scexyfg14M3lEiHPnqstnWsXhITunnniJs7T1jUsbGxOH78OMaNG2e0vVOnTjhw4ECq71u6dCmuXLmC3377DV988cUzzxMTE6MWPeHhTMIgeTVu3ULFrc/fCsPgJUfwZsuKqO/hiqolC6N8MUdYWZogTmxlAxSrrC2GeDQBJtwCYgysbKFMQ8DKThP2yDuapRooy/HUXeotxgB1B2rbYqO0ymwiqDb2Sfv6/KsdTwmxgRgnWsL3n3bbSyMUcdcL8vrZv4FStYyF2qGY5imQ2LysOxTVbi7u+mldz07/oS0yJ73uK0CdgVqmfTYjiUwi0qWc7fFGi6Te5/I3b1ethFpuh0bj72M3sfyIP26FRmPJvmtqaVIxycq2s6aVnRyxVXf6hSg399U7Wg19qcf/aY/qaOFpBjfDphTqu3fvIj4+HiVLljTaLs9v376d4nsuXbqkhH3v3r2wtk7f0MUy//zzz7NlzISYkrKuDlg5rDnGrzqL1ScDVetMPbbWlqhcvLAS7aolnVClhPZYrqiDaQRcEAvTPlkP+x4zktZjwrWCLPevacKtf5RtMv9b71KPj016T+Ax4JeeWpW1IeuM652LKD9zTFZJois10/WU8AI6Tn1aZN/eBdg4Jrnu9Ygj8uYR4NRvwLlV2ph3TgN2fgkMP6QdL5t4GBWLH3dorVDf71RVhURSopSLPUZ1qKKs7d0XQxKt7MPX7qtFZhL0a6BZ2ZWK08oWZArk1P98sPfSXfW8mKMt3u9UDf0blTPd/405Zn0nz2KVu5uUMltF1F9++WUlulWrPnGvpYPx48dj7Nixic8DAwNRvXr1LI6aENMgcccZL9VB22rFsdvvjopZXw6JQPTjBPgGhanFEDtrS+X6VOItIl7CSa2XdS0ES1P/EEl8VyxYWVJyqUucW8S7uIHoiRtaXM5iARvi2QF4/EizeEWExepVFrB+kedFtUz25KIriIXeYlTKY0wJ+Y0Sr4EsXb4CfNYCp37XrPri1ZL2O/O35saXanCZdI3/b8dlhEXHKSuvb/1nh+tEYNp7lVTLrYeP8NfRm2qRTOVFe6+ppVmlYsrK7lyjlLrJK2jcj4zFzK0X8fvhG6pHvK2VJV5vWUHd5DjbmyYObZYxanF9Ozg4YMWKFejTp0/i9tGjR6uY8+7du432f/jwIVxdXVVcWk9CQoISdtm2ZcsWtG/f/pnnZYya5DckLhnwIAoXgyOUhXApOFytX74Tgdi4lOc9F7KxUgKuxLukiHdhVCnhpJLUTC7gT5D/7ajYeDx89FhZlVJsQq1HxsIyLgq9m1Q1v4Qpcc3ri8nI+ndVgdhw4I3NgEfTDB/O/14UOszYhcfxOix7ozFaVy2e6XnAO/3u4M8j/srNq//VFwuyX8OyGNjIAxVycbqRqYiN0+ZDSxw6PDpObetSoxTGd/NS4aPcJE/EqG1tbdGgQQNs3brVSKjlea9evZ7a39nZGWfPnjXaJtniO3bswD///IOKFZPiNoQUJMSCkh8ZWST5xVDA/e9HGYm3rEsc7tHjeJVBnHyqj4OtlXKbVzEQbxFzEfDMzuGWaUXhMXFPhDZWNSARwQ2NSlqXx9BHTz8XgUqN0yGPMb1vbZgVhhXfxLXv1U0rFFO2cdL2E8sA+yJA1S6AtW2ah/t68wV1DVpVccu0SAsynUi+G7JIrPuvI/7469hNBIfFYMHuq2pp6emm3OKyT36zsnU6Hbb5ynxoH1y/F6W2VS/trOLQzSpnoAmOiTBp1rdMzxo8eDDmz5+PZs2aYeHChVi0aBHOnz+P8uXLK7e1uKqXLVuW4vsnT57MrG9CMmFd3bgfZSTel4IjcPVuRKrC6GhrBU8R7ydudM+ShQEdkoRXCatm+SYJ7RNL+NFj5V7MLOKWlCxmtRSyhaOdlbIOheVvN0XTjHQbMwUyp1ymuukLyXxfTYuni0u+1kta1ngK7v+T/g/QZ+4B5THfMKoVvEs7Z/v3YPsFLZYtmeN6JXArbIcXn1jZ0j89r+MbFIYv1vtg/+V7iZ/vo87V8EKDsiaNQ+cJi1ro378/7t27hylTpqiCJ1K8ZMOGDUqkBdnm7+9vyiESku8Q60oSz2TpUtN4esqNe5FG4i2P1+5GIjI2HqdvPlRLZhF3u4itzEXVi656brAuCU8uT9b1+9jbWD5lzUshGJlDPGHVWWwY3cr8XOCG6EVakAS5+q9qPcQjgoHD87SlVG0tA73WiyqWLvaT1HwXZJpVdou0/nsgMWpZpIPb8qP++PtYAO6Ex2DeritqEUteCql08C4Jm2wo8pGb3I2IwfdbLuKvo/5aHNraEm+1rIjh7TzVXPS8hMkrk+U2tKgJyXhc77oScM0Cv/TEfW5jbaGEVBPaJGFNev5EcAvZwLmQTbaKqVjpz83YrURlRDtPfNDZIIErLxAfB1zZDpz8TesnnqDN24WVrSqkcrxod7y0rRBsbGyw84O2KO2SCwVuntysbfcNxu+H/RMzoYXiTnbo37CcyoaWmQTmTExcPH7ef11lykvIReheqzTGdfUyq7GzzWUaUKgJyR9sPBuEYb+fUD28/xvVEl6lzLzKWWqoOdwrNNGWkq1PCNYVwfUyz6NJ31GAW5VcH5Yksv151B8rjt3E3Qhtipw4NlpVKY6G5V1V8lnFYo6o4OYAJzPIlNbpdNh8Plh5IiQ3Q6hVxkXFoRtXLApzg0KdBhRqQvIH8tP19q/HsdUnGHXKFcGqYc3Nau5rprh9Fr4b5qHkjX9R1OJJgRZxiw/da1KPyjbfYBXL3nc5yco2xK2wLSoo0XZUVby0dQf16JgLbuZzgaFqPrTMFxdKONnhoy5eqj6+ucxiyLMxakIIySwSt57aqyYOXbmnYucy7eZ1g6pdeZHwIl4YFNgHYTGdsajpHbSN2gpU6Zi0g1RJ2zQOqNYN8O6RK2OS2G63WqXVcv1uJDaeu40rdyLUuoRExNrWL8duPF1uVURTBLxCMQcDK1wT89SKt6SXkPBofL/5Iv4+flMlw0ndgLdbV8LQNpVz5QYht8g/n4QQUuCQalwfdfXCp2vO4dvNfuhUo1TuNCzJIWSa1L3IWFRyc0GLnj0Bq7eMdzi/Sius8uCGsVD/2EhuXQBn96TFqbTBuruWZZ5SsZcMIAI7rK1xudjw6Me4fjcK1+5FJoq39hilCouEhMeo5cgTa9cQKYkqlneSFa5Z5B5FHdLMaYh+HI+f9l/DnB2XVaKj0LOOOz7uUk1V8MtvUKgJIXmaVxp74N+Tgcqa+2T1Wfz0WqPs79udC0it7sX7tLKw4rZNMcu6bCOg8TtJzUT0Vdykk5nMl5Ma5KkhiWrS6MS5jCbiTYcB5RonWerRodrrUr89A0h8ulZZF7UkR+bOK+G+F6lmD4iAX7sXpR4lIVCqpcly6KqxiMufz92lUKL7vKKBkPvdDsf0jb4IePBI7VunrAs+61kdDcqbXxw6u6BQE0LyNBKD/OqFWug2e5+aX73uTBCer+OOvMb3W/xUKVhJ1Opcw7gHQiIlawDdvnm6frl0KAsLBMKCtMdwebyVtC0yRKuZLp3OZBFqv5R0jIubgVVvARVaAa/9l7R96yStjKqIu6GlbuuYrpKoMgOgjkMRlUOQUjvJRCvcQMBlkWxtKcwiy/4n859TssY/7loNveqYbxw6u6BQE0LyPJ4lnFSd5pnbLuLztefRytMNro5pV/0yt6Ic/5wIUOsTuntnzCMg7mzJCk8rM1wKrUTcfiLeTxbDIivS5czSRhNiQ0t9/2zNUn/qnNZaT24RcekprtadtXWx1KWHuSC12gOOAkXKa3XR9Tx6CFf7wnD1cFUd4JInCYr7X4m33pV+L0nEhbdaVcI7bSrBwbZgSFjB+JSEkHyPxE7/O3MLl0IiMG2DL757sQ7yCtM3XlDJUDLfN7lwZQtSqrSIh7akRKM3gQavA3HRSdvEAm81VrPIww0EXtqFJsRp1dVS6lgmRVv03NgP/Psu4NkRGPRP0vYZ1YHHkVpnMiOxd4KFvTPc7JzgZueChrLd2Qko7gxUaAmdawV1nfK7BZ0cCjUhJF8g2cniAu83/yD+OR6A3nXLoGUV8+gnnBZ7L93Bnot3YGNlgY+6mLBwi1jmhrXKxb3d4bOn94uJ0OLZUstcLHFZJMat1sONu4c5uAEV2wCl6xiXVBWRFuRRFrH2n0XfxbAoWlHzuF/bA/w7AvB8zrh1qngOnlE/PS9CoSaE5BskoWhw0/JYdvAGJqw+i81jWmd5ClBOIo1TvtxwQa0Palo+1zs4ZQq7wtqSHqp10ZbkJVU/ufNE6J8IvhL68GSiH2b8mqtWWloR7AM8vKGVYdUjpvZ3VbQe6CW8tfao6rEa4FbN+CYkj0GhJoTkKz7sXA1bzger6lSztl3E+G7eMFdWnwxU8Wkne2uMap/71cdMhli91sUAx0w2VKnTX0uss7ZP2hZ+G4h+qC0i4hc3GbzBQhN6Ee9EAfcC3KrmCQGnUBNC8hUyXWhq75r4v2XHsHjfNTW/tmaZp6cOmRqZCyyZ3oIkwuWl5DeTU8gVqNjKeJtMWfvwChDiC9y5oC0h8ugLRN0DHlzXluQC/uaWpGlq969qFryZCTiFmhCS75CeypKYtf5sEMatOoM1w1uoblHmxJJ91xAUGq0KtLzWvIKph5M/cJSYeKunRTzybpKAq0e/JAEvWilpv2M/AQf+BzR+G+j2rbYtNhLw/e+JC900Ak6hJoTkSyY9X10lap0LDFNVrN5ubVxRy9QtGKWNpPBB56rm3aYzvwu4o0HCoYUlUKio5hY3jIevflu/A/DxNc2iz0XM6xaTEEKyiRJO9pjYXYtPz9h6UXWDMhd+2H4JETFxqFnGWRXsICbCMdmsgI5TNCFu8FrSNl0CUL6FJuCOxXNdpAUKNSEk3/JSw3JoVqmYqvglWeDm0Czw6p0I1YlKmNDVu8DNCc4TWBp4OKRQy+sbNAEfecw0wzHJWQkhJBeQCl9f9q2l5lhLi8ZVJwJNPSR8vekC4hJ0aO9VAs09zX+eNzFApn6ZAAo1ISRfIw0dxjynTX2aut5HxYdNxdHr97H5fDDEiB7f1SAOSkgaUKgJIfme/2tVCd6lnfEw6jGm/udjkjGI2/3LDb5qvX+jcqhS0skk4yB5Dwo1ISTfIy0jv+pbS1my/566hZ1+Ibk+hg1nb+Ok/0M42Frhveeq5vr5Sd6FQk0IKRBIq8XXW1RU65+sPofImLhcO3dsXAK+2Xwh0bov4WxQUYuQZ0ChJoQUGMZ2rKoKjEif4++3XMy18/526AZu3ItCcSc7vN3aoMAGIemAQk0IKTA42lljWp+aan3pgWs4dfNhjp8z9NFj/LDjkloXl7eMgZCMQKEmhBQo2lYrgd513VWzpXErz+BxfEKOnm/urssqic2zRGG81LBsjp6L5E8o1ISQAsenParD1cEGF26HY+Geqzl2noAHUVi6/7pal+lY5lZvnOQNTP6tmTt3LipWrAh7e3s0aNAAe/fuTXXfffv2oUWLFihWrBgKFSoELy8vzJw5M1fHSwjJ+xQrbKfEWpi9/ZKqFpYTSBxcEsmaViqqCpwQkueE+q+//sKYMWMwceJEnDx5Eq1atULXrl3h76+V10uOo6MjRowYgT179sDX1xeffPKJWhYuXJjrYyeE5G361CuDVlXclJCOX3UWCQnZW170XGCo6jctTOxWXVVJIyQzWOhMWPy2SZMmqF+/PubNm5e4zdvbG71798b06dPTdYy+ffsqAf/111/TtX9AQADKlSuHmzdvomxZxosIKcjcvB+FTjP34NHjeDXPekBjj2w5rvysvrL4MA5cuYdedd0xe0C9bDkuyT9kRItMZlHHxsbi+PHj6NSpk9F2eX7gwIF0HUOscNm3TZs2qe4TExODsLCwxCU8PDzLYyeE5A/KFXXA+5204iPTNvgiJCw6W467y++OEmlbK0t80KlathyTFFxMJtR3795FfHw8SpYsabRdnt++fTvN98rdh52dHRo2bIh3330Xb731Vqr7imXu4uKSuFSvrsWlCCFEeK15BdQq44Lw6DhMXnc+y8eLi0/A9I1aqdDXWlRQNwOE5OlksuRxG3EZPSuWIwlnx44dw/z58zFr1iz8+eefqe47fvx4hIaGJi4+Pqap80sIMU8kE/urF2rBytJClfnccj5tQ+FZ/HM8ABeDI+BSyAbvtvXMtnGSgovJZt67ubnBysrqKes5JCTkKSs7OZIlLtSqVQvBwcGYPHkyBg4cmOK+YnnLokfc34QQYkgNdxdV2nP+7iv47N/zaFa5GJzsbTJ8HClL+v1WreLZyPaecHHI+DEIMRuL2tbWVk3H2rp1q9F2ed68efN0H0cscIlDE0JIVpBWmOWLOeB2WDS+2eSXqWMs2nsVd8JjUK5oIQxuVj7bx0gKJiZ1fY8dOxaLFy/GTz/9pKZbvffee2pq1tChQxPd1q+++mri/nPmzMG6detw6dIltSxduhTfffcdBg0aZMJPQQjJD9jbWGF6n1pq/ddDN3Ds+v0MvT8kPDqxeMpHnb1gZ22VI+MkBQ+TFp3t378/7t27hylTpiAoKAg1a9bEhg0bUL68dicq2wznVCckJCjxvnbtGqytrVG5cmV89dVXeOedd0z4KQgh+YXmnm54sUFZrDgegHGrzmL9qJbpFtyZWy8hKjZedenqUbt0jo+VFBxMOo/aFHAeNSEkLR5GxeK5GbtxNyIWoztUwXsdn907+lJwODrP2gOpmfL3O83QuGLRXBkrybvkiXnUhBBijhRxsMWknjUSG2qICD+LrzZeUCLdsXpJijTJdijUhBCSDHFdd/AqgcfxOuUCT6u86MEr97D9Qoia3jWuq1eujpMUDCjUhBCSDKnlMLV3TTjaWuH4jQf4/fCNFPcTAf9yg1bcZGDjcqhcvHAuj5QUBCjUhBCSAu5FCuGjLpqF/PUmPwSFPnpqn3VnbuFsYKgS9NEdnh3LJiQzUKgJISQVBjUtj3oeRRARE4dP15xXdRv0RD+OT5xvPaxtZRR3SiqsREh2QqEmhJBUkLjz1y/Uho2VBbb5BmPjuaRKissOXkfgw0co5WyPN1tWMuk4Sf6GQk0IIWlQtaQThrWprNalvGho1GM1hevHHZfVtrGdqqKQLYubkHxa8IQQQvICw9t54r+zQbh6J1J1xnK0s0ZYdBy8Sjnhhfqsx0ByFlrUhBCSjvKiX/WtrdaXH72JXw5cV+vju3kr9zghOQmFmhBC0oEUMnm5iYdaj0vQoVUVN7SpWtzUwyIFAAo1IYSkEylo4u5iD1srSxY3IbkGY9SEEJJOnO1tsHZkS0REx6GCm6Oph0MKCBRqQgjJAG6F7dRCSG5B1zchhBBixlCoCSGEEDOGQk0IIYSYMRRqQgghxIyhUBNCCCFmTIHL+k5ISFCPQUFBph4KIYSQAkrQEw3Sa1JaFDihDg4OVo+NGzc29VAIIYQUcIKDg+HhoVW8Sw0LnWGD1QJAXFwcTp48iZIlS8LSMmue//DwcFSvXh0+Pj5wcnLKtjHmZ3jNMgavV8bg9coYvF6mu15iSYtI16tXD9bWadvMBU6os5OwsDC4uLggNDQUzs7Oph5OnoDXLGPwemUMXq+MweuVN64Xk8kIIYQQM4ZCTQghhJgxFOosYGdnh0mTJqlHkj54zTIGr1fG4PXKGLxeeeN6MUZNCCGEmDG0qAkhhBAzhkJNCCGEmDEUakIIIcSMoVBngblz56JixYqwt7dHgwYNsHfvXlMPyWzZs2cPevbsCXd3d1hYWGDNmjWmHpLZMn36dDRq1EgVVChRogR69+4NPz8/Uw/LbJk3bx5q166t5rXK0qxZM2zcuNHUw8pT3zf5nxwzZoyph2K2TJ48WV0jw6VUqVK5dn4KdSb566+/1Bd74sSJqtJZq1at0LVrV/j7+5t6aGZJZGQk6tSpgx9//NHUQzF7du/ejXfffReHDh3C1q1bVTW9Tp06qWtInqZs2bL46quvcOzYMbW0b98evXr1wvnz5009NLPn6NGjWLhwobrRIWlTo0YNVZ9bv5w9exa5hmR9k4zTuHFj3dChQ422eXl56caNG2eyMeUV5Gu3evVqUw8jzxASEqKu2e7du009lDyDq6urbvHixaYehlkTHh6uq1Klim7r1q26Nm3a6EaPHm3qIZktkyZN0tWpU8dk56dFnQliY2Nx/PhxZeUYIs8PHDhgsnGR/ImUKxSKFi1q6qGYPfHx8Vi+fLnyPogLnKSOeG26d++O5557ztRDyRNcunRJhe4k3DlgwABcvXo1185d4LpnZQd3795VPwjS2MMQeX779m2TjYvkP8QBMXbsWLRs2RI1a9Y09XDMFnFDijBHR0ejcOHCWL16tWqeQFJGbmZOnDihXN/k2TRp0gTLli1D1apVVSONL774As2bN1fhlWLFiiGnoVBnAUkoSP6jmnwbIVlhxIgROHPmDPbt22fqoZg11apVw6lTp/Dw4UOsXLkSQ4YMUbF+ivXT3Lx5E6NHj8aWLVtUIix5NpJ/pKdWrVrqprBy5cr45Zdf1I10TkOhzgRubm6wsrJ6ynoOCQl5ysomJLOMHDkSa9euVRnzkjBFUsfW1haenp5qvWHDhspSnD17NhYsWGDqoZkdEraT3yqZqaJHPITyPZNkz5iYGPX7RlLH0dFRCba4w3MDxqgz+aMgX3LJyDVEnos7hJCsIJ4ZsaRXrVqFHTt2qJgYyfg1FMEhT9OhQwcVKhAPhH6Rm5tXXnlFrVOkn418t3x9fVG6dGnkBrSoM4m4OwYPHqy+4OIGkSkOMjVr6NChph6aWRIREYHLly8nPr927Zr6UZAEKQ8PD5OOzRyTfP744w/8+++/ai613nMjfXALFSpk6uGZHRMmTFCuyXLlyiE8PFzFX3ft2oVNmzaZemhmiXynkuc7iIUosVbmQaTMBx98oOpAyG+VeCMkRi29qSXEkhtQqDNJ//79ce/ePUyZMkXNqZMv+IYNG1C+fHlTD80skfmt7dq1S3yuj+vIF/3nn3824cjMs4CH0LZtW6PtS5cuxWuvvWaiUZkvktwjN83yfyg3MzInWES6Y8eOph4ayScEBARg4MCBKpG4ePHiaNq0qapzkFu/9+yeRQghhJgxjFETQgghZgyFmhBCCDFjKNSEEEKIGUOhJoQQQswYCjUhhBBixlCoCSGEEDOGQk0IIYSYMRRqQgghxIyhUBNCcgzpJrdmzRpTD4OQPA2FmpB8ipQbFaFMvnTp0sXUQyOEZADW+iYkHyOiLDXCDbGzszPZeAghGYcWNSH5GBHlUqVKGS2urq7qNbGupQGIdJ6SrlzSTnPFihVG75d2iO3bt1evS3elt99+W3VCM+Snn35CjRo11Lmk7Z+06DREGhn06dMHDg4OqFKliuqxrefBgweqvaI0OpBzyOvJbywIKehQqAkpwHz66ad44YUXcPr0aQwaNEh1CJI+u0JUVJSyyEXYjx49qkR827ZtRkIsQi9tOUXARdRFhD09PY3O8fnnn+Oll17CmTNn0K1bNyXM9+/fTzy/j48PNm7cqM4rx3Nzc8vlq0CImSPdswgh+Y8hQ4borKysdI6OjkbLlClT1Ovy7z906FCj9zRp0kQ3bNgwtb5w4UKdq6urLiIiIvH19evX6ywtLXW3b99Wz93d3XUTJ05MdQxyjk8++STxuRzLwsJCt3HjRvW8Z8+eutdffz2bPzkh+QvGqAnJx0gPcH1/az1FixZNXG/WrJnRa/L81KlTal0s3Dp16sDR0THx9RYtWiAhIQF+fn7KdX7r1i106NAhzTFIf2g9ciwnJyeEhISo58OGDVMW/YkTJ9CpUyf07t0bzZs3z+KnJiR/QaEmJB8jwpjcFf0sRIAFMYj16yntIzHl9GBjY/PUe0XsBYmP37hxA+vXr1dudRF9caV/9913GRozIfkZxqgJKcAcOnToqedeXl5qvXr16sq6joyMTHx9//79sLS0RNWqVZVlXKFCBWzfvj1LY5BEMplK9ttvv2HWrFlYuHBhlo5HSH6DFjUh+ZiYmBjcvn3baJu1tXViwpYkiDVs2BAtW7bE77//jiNHjmDJkiXqNUn6mjRpEoYMGYLJkyfjzp07GDlyJAYPHoySJUuqfWT70KFDUaJECWUdh4eHKzGX/dLDZ599hgYNGqiscRnrf//9B29v72y/DoTkZSjUhORjNm3apKZMGVKtWjVcuHAhMSN7+fLlGD58uJq6JWItlrQg06k2b96M0aNHo1GjRuq5xJNnzJiReCwR8ejoaMycORMffPCBugHo169fusdna2uL8ePH4/r168qV3qpVKzUeQkgSFpJRZvCcEFJAkFjx6tWrVQIXIcR8YYyaEEIIMWMo1IQQQogZwxg1IQUURr0IyRvQoiaEEELMGAo1IYQQYsZQqAkhhBAzhkJNCCGEmDEUakIIIcSMoVATQgghZgyFmhBCCDFjKNSEEEKIGUOhJoQQQmC+/D9ORgj5Qwut4AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 87.40%\n",
      "Validation accuracy: 85.23%\n",
      "Test accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "    \n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
